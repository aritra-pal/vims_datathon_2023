{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47a777da",
   "metadata": {},
   "source": [
    "# VIMS Datathon 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0df08ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "path_imgs = \"./Test_Dataset_100/test_images\" #Path to test images\n",
    "\n",
    "path_gt_labels = \"./Test_Dataset_100/test_2.json\" # Path to gt_json file\n",
    "\n",
    "model = YOLO('./model/bestYOLOv8Lresult.pt')  # path to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b3d81c",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccb59f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/04804.jpg: 640x480 1 Crane, 47.5ms\n",
      "Speed: 2.1ms preprocess, 47.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02147.jpg: 480x640 1 Scraper, 44.9ms\n",
      "Speed: 1.1ms preprocess, 44.9ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02132.jpg: 384x640 1 Excavator, 1 Truck, 47.4ms\n",
      "Speed: 0.8ms preprocess, 47.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/09335.jpg: 384x640 1 Excavator, 1 Truck, 7.1ms\n",
      "Speed: 0.8ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/03168.jpg: 640x384 2 Excavators, 46.1ms\n",
      "Speed: 1.1ms preprocess, 46.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02936.jpg: 384x640 1 Excavator, 7.3ms\n",
      "Speed: 0.9ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/ppe_0529.jpg: 640x448 1 worker, 47.0ms\n",
      "Speed: 0.9ms preprocess, 47.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/07759.jpg: 384x640 1 Truck, 7.4ms\n",
      "Speed: 0.8ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/03776.jpg: 480x640 1 Crane, 8.2ms\n",
      "Speed: 1.3ms preprocess, 8.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/05644.jpg: 480x640 1 Excavator, 7.9ms\n",
      "Speed: 0.9ms preprocess, 7.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/05675.jpg: 608x640 1 Excavator, 1 Truck, 45.8ms\n",
      "Speed: 0.9ms preprocess, 45.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/ppe_1065.jpg: 640x608 1 worker, 45.4ms\n",
      "Speed: 1.2ms preprocess, 45.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02193.jpg: 384x640 1 Excavator, 7.4ms\n",
      "Speed: 0.8ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/ppe_0898.jpg: 416x640 2 workers, 45.7ms\n",
      "Speed: 1.2ms preprocess, 45.7ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/01900.jpg: 320x640 1 Bulldozer, 47.4ms\n",
      "Speed: 0.7ms preprocess, 47.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/08262.jpg: 320x640 1 Crane, 6.4ms\n",
      "Speed: 0.7ms preprocess, 6.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02027.jpg: 384x640 1 Excavator, 7.4ms\n",
      "Speed: 0.7ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/ppe_0475.jpg: 448x640 2 workers, 44.3ms\n",
      "Speed: 0.9ms preprocess, 44.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/07946.jpg: 384x640 1 Excavator, 2 Trucks, 7.4ms\n",
      "Speed: 0.7ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/09384.jpg: 352x640 3 Scrapers, 46.0ms\n",
      "Speed: 0.4ms preprocess, 46.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/ppe_0133.jpg: 448x640 6 workers, 8.1ms\n",
      "Speed: 1.1ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02924.jpg: 384x640 1 Excavator, 1 Truck, 7.4ms\n",
      "Speed: 0.8ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/08004.jpg: 384x640 2 Scrapers, 2 Compactors, 7.1ms\n",
      "Speed: 0.8ms preprocess, 7.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/01698.jpg: 352x640 1 Excavator, 6.9ms\n",
      "Speed: 0.4ms preprocess, 6.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/04150.jpg: 384x640 1 Excavator, 1 Truck, 7.4ms\n",
      "Speed: 0.8ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/07070.jpg: 384x640 1 Bulldozer, 7.1ms\n",
      "Speed: 0.8ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/06547.jpg: 384x640 1 Excavator, 1 Truck, 7.0ms\n",
      "Speed: 0.8ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/08636.jpg: 384x640 1 Crane, 7.0ms\n",
      "Speed: 0.8ms preprocess, 7.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/08580.jpg: 384x640 1 Crane, 7.1ms\n",
      "Speed: 0.8ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/06704.jpg: 384x640 1 Excavator, 7.1ms\n",
      "Speed: 0.6ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/05416.jpg: 384x640 1 Excavator, 2 Trucks, 7.1ms\n",
      "Speed: 0.8ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/07108.jpg: 384x640 2 Excavators, 2 Trucks, 7.1ms\n",
      "Speed: 0.7ms preprocess, 7.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02068.jpg: 384x640 1 Excavator, 2 Trucks, 7.1ms\n",
      "Speed: 0.8ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02527.jpg: 384x640 1 Bulldozer, 7.1ms\n",
      "Speed: 0.5ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/09731.jpg: 384x640 1 Excavator, 2 Trucks, 7.1ms\n",
      "Speed: 0.8ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/07627.jpg: 384x640 1 Excavator, 1 Truck, 6.6ms\n",
      "Speed: 0.6ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/00118.jpg: 384x640 1 Excavator, 2 Trucks, 6.6ms\n",
      "Speed: 0.6ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/00039.jpg: 480x640 1 Scraper, 7.9ms\n",
      "Speed: 1.1ms preprocess, 7.9ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02257.jpg: 384x640 1 Excavator, 1 Truck, 6.9ms\n",
      "Speed: 0.5ms preprocess, 6.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/06505.jpg: 384x640 1 Scraper, 6.6ms\n",
      "Speed: 0.7ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/07944.jpg: 384x640 3 Excavators, 3 Trucks, 6.6ms\n",
      "Speed: 0.8ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02263.jpg: 384x640 2 Excavators, 1 Truck, 6.6ms\n",
      "Speed: 0.7ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/01862.jpg: 480x640 1 Excavator, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/03627.jpg: 384x640 1 Excavator, 1 Truck, 6.9ms\n",
      "Speed: 0.8ms preprocess, 6.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02130.jpg: 384x640 1 Excavator, 6.6ms\n",
      "Speed: 0.8ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/03048.jpg: 384x640 1 Scraper, 6.6ms\n",
      "Speed: 0.8ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/04964.jpg: 384x640 1 Excavator, 1 Truck, 6.6ms\n",
      "Speed: 0.5ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/ppe_0429.jpg: 416x640 19 workers, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/05103.jpg: 416x640 1 Truck, 7.1ms\n",
      "Speed: 1.1ms preprocess, 7.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/01440.jpg: 384x640 1 Scraper, 7.0ms\n",
      "Speed: 0.8ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/09878.jpg: 384x640 1 Scraper, 6.6ms\n",
      "Speed: 0.8ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02590.jpg: 384x640 1 Excavator, 6.6ms\n",
      "Speed: 0.8ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02537.jpg: 480x640 1 Scraper, 7.8ms\n",
      "Speed: 0.9ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/ppe_0345.jpg: 448x640 3 workers, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/ppe_0261.jpg: 448x640 6 workers, 7.3ms\n",
      "Speed: 0.7ms preprocess, 7.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/08571.jpg: 384x640 1 Excavator, 7.0ms\n",
      "Speed: 0.6ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/06546.jpg: 384x640 1 Excavator, 1 Bulldozer, 6.6ms\n",
      "Speed: 0.8ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/05851.jpg: 480x640 1 Scraper, 7.7ms\n",
      "Speed: 0.8ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/08145.jpg: 384x640 1 Bulldozer, 6.9ms\n",
      "Speed: 0.8ms preprocess, 6.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/07368.jpg: 320x640 1 Crane, 1 Bulldozer, 6.3ms\n",
      "Speed: 0.8ms preprocess, 6.3ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02423.jpg: 384x640 1 Excavator, 7.0ms\n",
      "Speed: 0.8ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/08407.jpg: 320x640 1 Excavator, 6.3ms\n",
      "Speed: 0.6ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02995.jpg: 640x640 1 Truck, 10.9ms\n",
      "Speed: 1.1ms preprocess, 10.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/00995.jpg: 384x640 1 Truck, 7.0ms\n",
      "Speed: 0.6ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/07563.jpg: 384x640 1 Excavator, 1 Compactor, 6.6ms\n",
      "Speed: 0.8ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/04353.jpg: 512x640 1 Crane, 47.1ms\n",
      "Speed: 1.5ms preprocess, 47.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/04780.jpg: 384x640 1 Excavator, 7.0ms\n",
      "Speed: 0.5ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02567.jpg: 384x640 1 Excavator, 6.6ms\n",
      "Speed: 0.7ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/00101.jpg: 480x640 1 Crane, 7.7ms\n",
      "Speed: 0.8ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/09205.jpg: 384x640 1 Crane, 6.9ms\n",
      "Speed: 0.8ms preprocess, 6.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/09624.jpg: 352x640 2 Scrapers, 6.5ms\n",
      "Speed: 0.3ms preprocess, 6.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/04894.jpg: 352x640 1 Excavator, 6.2ms\n",
      "Speed: 0.3ms preprocess, 6.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02383.jpg: 384x640 1 Truck, 6.9ms\n",
      "Speed: 0.6ms preprocess, 6.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/03095.jpg: 384x640 1 Scraper, 6.6ms\n",
      "Speed: 0.8ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/03140.jpg: 384x640 1 Excavator, 6.6ms\n",
      "Speed: 0.7ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/08855.jpg: 384x640 1 Scraper, 6.6ms\n",
      "Speed: 0.8ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/01111.jpg: 384x640 1 Bulldozer, 1 Truck, 6.6ms\n",
      "Speed: 0.7ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/06700.jpg: 384x640 1 Scraper, 6.6ms\n",
      "Speed: 0.8ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/05809.jpg: 384x640 1 Excavator, 1 Truck, 6.6ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 0.7ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/ppe_0031.jpg: 384x640 1 worker, 6.6ms\n",
      "Speed: 0.8ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/00814.jpg: 384x640 1 Excavator, 6.6ms\n",
      "Speed: 0.8ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02722.jpg: 384x640 1 Crane, 4 Excavators, 1 Truck, 6.6ms\n",
      "Speed: 0.8ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/05542.jpg: 384x640 1 Compactor, 6.6ms\n",
      "Speed: 0.8ms preprocess, 6.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/ppe_0403.jpg: 640x448 1 worker, 7.6ms\n",
      "Speed: 0.8ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/04854.jpg: 448x640 1 Bulldozer, 7.6ms\n",
      "Speed: 0.9ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/05197.jpg: 384x640 1 Compactor, 6.9ms\n",
      "Speed: 0.8ms preprocess, 6.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/00007.jpg: 384x640 1 Excavator, 6.6ms\n",
      "Speed: 0.6ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/08568.jpg: 384x640 1 Excavator, 1 Compactor, 6.6ms\n",
      "Speed: 0.8ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/03941.jpg: 384x640 1 Bulldozer, 6.6ms\n",
      "Speed: 0.8ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/08359.jpg: 384x640 1 Scraper, 1 Truck, 6.6ms\n",
      "Speed: 0.7ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/00078.jpg: 480x640 1 Compactor, 7.7ms\n",
      "Speed: 0.7ms preprocess, 7.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/ppe_1042.jpg: 640x640 1 worker, 10.8ms\n",
      "Speed: 1.1ms preprocess, 10.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/00331.jpg: 384x640 1 Truck, 6.9ms\n",
      "Speed: 0.6ms preprocess, 6.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/09904.jpg: 384x640 1 Truck, 6.6ms\n",
      "Speed: 0.8ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/05914.jpg: 320x640 1 Excavator, 6.3ms\n",
      "Speed: 0.8ms preprocess, 6.3ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/03876.jpg: 384x640 2 Excavators, 8 Trucks, 7.0ms\n",
      "Speed: 0.8ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02528.jpg: 448x640 1 Excavator, 7.6ms\n",
      "Speed: 0.7ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/08692.jpg: 384x640 2 Scrapers, 1 Compactor, 6.9ms\n",
      "Speed: 0.7ms preprocess, 6.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/04499.jpg: 384x640 1 Excavator, 6.6ms\n",
      "Speed: 0.8ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/05161.jpg: 448x640 1 Crane, 7.7ms\n",
      "Speed: 1.2ms preprocess, 7.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "test_files = os.listdir(path_imgs)\n",
    "\n",
    "coco_dt = []\n",
    "for file in test_files:\n",
    "    result = model(os.path.join(path_imgs,file))\n",
    "    boxes = result[0].boxes  # Boxes object for bbox outputs \n",
    "    #print(results)\n",
    "    #print(file)\n",
    "    #print(boxes.xyxy)\n",
    "    #print(boxes.cls)\n",
    "    #print(boxes.conf)\n",
    "    for k in range(len(boxes.cls)):\n",
    "        A, B, C, D  = boxes.xyxy[k].tolist()\n",
    "        bbox = [A, B, (C-A), (D-B)]\n",
    "        coco_dt.append({\n",
    "              'image_id': file,\n",
    "              'category_id': boxes.cls[k].cpu().detach().numpy().item(),\n",
    "              #'bbox': boxes.xyxy[k].tolist(),\n",
    "              'bbox': bbox,\n",
    "              'score': boxes.conf[k].cpu().detach().numpy().item()\n",
    "              })\n",
    "    \n",
    "#print(coco_dt)\n",
    "\n",
    "with open(\"./detections.json\", \"w\") as outfile:\n",
    "    json.dump(coco_dt, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0d313b",
   "metadata": {},
   "source": [
    "## Mapping with Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d53321ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Crane': 1, 'Excavator': 2, 'Bulldozer': 3, 'Scraper': 4, 'Truck': 5, 'worker': 7}\n"
     ]
    }
   ],
   "source": [
    "predict_json = \"./detections.json\"\n",
    "\n",
    "with open(predict_json) as json_file:\n",
    "    predictions = json.load(json_file)\n",
    "\n",
    "gt_json = path_gt_labels\n",
    "with open(gt_json) as json_file:\n",
    "    gts = json.load(json_file)\n",
    "\n",
    "gt_ims = {}\n",
    "\n",
    "for im in gts['images']:\n",
    "    gt_ims[im['file_name']] = im['id']\n",
    "\n",
    "\n",
    "for prediction in predictions:\n",
    "    if prediction['image_id'] in gt_ims:\n",
    "        prediction['image_id']= gt_ims[prediction['image_id']]\n",
    "\n",
    "gt_cats = {}\n",
    "#dt_cats = {'Crane': 1, 'Excavator': 2, 'Bulldozer': 3, 'Scraper': 4, 'Truck': 5, 'Compactor': 6, 'worker': 7}\n",
    "\n",
    "for cat in gts['categories']:\n",
    "    gt_cats[cat['name']] = cat['id']\n",
    "\n",
    "print(gt_cats)\n",
    "for prediction in predictions:\n",
    "    if prediction['category_id'] == 1:\n",
    "        prediction['category_id']= float(gt_cats['Crane'])\n",
    "    elif prediction['category_id'] == 2:\n",
    "        prediction['category_id']= float(gt_cats['Excavator'])\n",
    "    elif prediction['category_id'] == 3:\n",
    "        prediction['category_id']= float(gt_cats['Bulldozer'])\n",
    "    elif prediction['category_id'] == 4:\n",
    "        prediction['category_id']= float(gt_cats['Scraper'])\n",
    "    elif prediction['category_id'] == 5:\n",
    "        prediction['category_id']= float(gt_cats['Truck'])\n",
    "    elif prediction['category_id'] == 7:\n",
    "        prediction['category_id']= float(gt_cats['worker'])\n",
    "    else:\n",
    "        if \"Compactor\" in gt_cats.keys():\n",
    "            prediction['category_id']= float(gt_cats['Compactor'])\n",
    "        else:\n",
    "            prediction['category_id'] = 0\n",
    "    \n",
    "\n",
    "with open(\"detections_new.json\", \"w\") as outfile:\n",
    "    json.dump(predictions, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689b9a2b",
   "metadata": {},
   "source": [
    "## Evaluation: mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc67faff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.03s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.02s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.917\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.989\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.971\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.783\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.941\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.748\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.921\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.927\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.799\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.950\n",
      "\n",
      " mAP (Overall) 0.9890633318787591\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "predict_json_new = \"./detections_new.json\"\n",
    "\n",
    "coco_gt = COCO(path_gt_labels)\n",
    "coco_dt = coco_gt.loadRes(predict_json_new)\n",
    "coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()\n",
    "\n",
    "# Get mAP\n",
    "mAP = coco_eval.stats[1]\n",
    "print(\"\\n mAP (Overall)\", mAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f82eb8",
   "metadata": {},
   "source": [
    "## Evaluation: mean IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "013ab2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU of Class1_Crane: 0.967513972057842\n",
      "IoU of Class2_Excavator: 0.9601294157022492\n",
      "IoU of Class3_Bulldozer: 0.9576445557302979\n",
      "IoU of Class4_Scraper: 0.971295425935968\n",
      "IoU of Class5_Truck: 0.9502396226213781\n",
      "IoU of Class7_worker: 0.9669954908158426\n",
      "\n",
      "meanIoU (Overall): 0.962303080477263\n",
      "\n",
      "Mean IoU {1: 0.967513972057842, 2: 0.9601294157022492, 3: 0.9576445557302979, 4: 0.971295425935968, 5: 0.9502396226213781, 7: 0.9669954908158426, 'Overall': 0.962303080477263}\n"
     ]
    }
   ],
   "source": [
    "predict_json_new = \"./detections_new.json\"\n",
    "\n",
    "with open(predict_json_new) as json_file:\n",
    "    predictions = json.load(json_file)\n",
    "\n",
    "gt_categories_id = list(gt_cats.values())\n",
    "gt_categories_name = list(gt_cats.keys())\n",
    "\n",
    "cls_iou = defaultdict(list)\n",
    "mIoU = {}\n",
    "overall_miou = []\n",
    "\n",
    "for pred in predictions:\n",
    "    iou = coco_eval.computeIoU(pred['image_id'],pred['category_id'])\n",
    "    if len(iou)>0:\n",
    "        iou = np.max(iou)\n",
    "        for cats in gt_categories_id:\n",
    "            if pred['category_id'] == cats:\n",
    "                cls_iou[cats].append(iou)\n",
    "\n",
    "for cats in gt_categories_id:\n",
    "    cls_miou = np.nanmean(cls_iou[cats])\n",
    "    mIoU[cats]=cls_miou\n",
    "    print(\"IoU of Class{}_{}: {}\".format(cats, gt_categories_name[gt_categories_id.index(cats)], cls_miou))\n",
    "    overall_miou.append(cls_miou)\n",
    "overall_miou = np.nanmean(overall_miou)\n",
    "\n",
    "print(\"\\nmeanIoU (Overall):\", overall_miou)\n",
    "mIoU[\"Overall\"]=overall_miou\n",
    "print(\"\\nMean IoU\", mIoU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0758e4",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a96c5a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/04804.jpg: 640x480 1 Crane, 7.7ms\n",
      "Speed: 0.8ms preprocess, 7.7ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02147.jpg: 480x640 1 Scraper, 7.8ms\n",
      "Speed: 0.7ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02132.jpg: 384x640 1 Excavator, 1 Truck, 7.0ms\n",
      "Speed: 0.6ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/09335.jpg: 384x640 1 Excavator, 1 Truck, 6.6ms\n",
      "Speed: 0.6ms preprocess, 6.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/03168.jpg: 640x384 2 Excavators, 6.8ms\n",
      "Speed: 0.9ms preprocess, 6.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02936.jpg: 384x640 1 Excavator, 7.0ms\n",
      "Speed: 0.8ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/ppe_0529.jpg: 640x448 1 worker, 7.5ms\n",
      "Speed: 0.8ms preprocess, 7.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/07759.jpg: 384x640 1 Truck, 7.0ms\n",
      "Speed: 0.6ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/03776.jpg: 480x640 1 Crane, 7.8ms\n",
      "Speed: 1.1ms preprocess, 7.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/05644.jpg: 480x640 1 Excavator, 7.5ms\n",
      "Speed: 0.9ms preprocess, 7.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/05675.jpg: 608x640 1 Excavator, 1 Truck, 11.6ms\n",
      "Speed: 0.9ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/ppe_1065.jpg: 640x608 1 worker, 11.6ms\n",
      "Speed: 1.2ms preprocess, 11.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02193.jpg: 384x640 1 Excavator, 7.0ms\n",
      "Speed: 0.7ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/ppe_0898.jpg: 416x640 2 workers, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/01900.jpg: 320x640 1 Bulldozer, 6.4ms\n",
      "Speed: 0.8ms preprocess, 6.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/08262.jpg: 320x640 1 Crane, 6.0ms\n",
      "Speed: 0.7ms preprocess, 6.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02027.jpg: 384x640 1 Excavator, 6.9ms\n",
      "Speed: 0.6ms preprocess, 6.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/ppe_0475.jpg: 448x640 2 workers, 7.6ms\n",
      "Speed: 0.9ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/07946.jpg: 384x640 1 Excavator, 2 Trucks, 6.9ms\n",
      "Speed: 0.6ms preprocess, 6.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/09384.jpg: 352x640 3 Scrapers, 6.5ms\n",
      "Speed: 0.3ms preprocess, 6.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/ppe_0133.jpg: 448x640 6 workers, 7.6ms\n",
      "Speed: 0.9ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02924.jpg: 384x640 1 Excavator, 1 Truck, 6.9ms\n",
      "Speed: 0.6ms preprocess, 6.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/08004.jpg: 384x640 2 Scrapers, 2 Compactors, 6.6ms\n",
      "Speed: 0.6ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/01698.jpg: 352x640 1 Excavator, 6.5ms\n",
      "Speed: 0.5ms preprocess, 6.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/04150.jpg: 384x640 1 Excavator, 1 Truck, 7.0ms\n",
      "Speed: 0.8ms preprocess, 7.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/07070.jpg: 384x640 1 Bulldozer, 6.6ms\n",
      "Speed: 0.6ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/06547.jpg: 384x640 1 Excavator, 1 Truck, 6.6ms\n",
      "Speed: 0.6ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/08636.jpg: 384x640 1 Crane, 6.6ms\n",
      "Speed: 0.6ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/08580.jpg: 384x640 1 Crane, 6.6ms\n",
      "Speed: 0.8ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/06704.jpg: 384x640 1 Excavator, 6.6ms\n",
      "Speed: 0.8ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/05416.jpg: 384x640 1 Excavator, 2 Trucks, 6.6ms\n",
      "Speed: 0.6ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/07108.jpg: 384x640 2 Excavators, 2 Trucks, 6.6ms\n",
      "Speed: 0.6ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02068.jpg: 384x640 1 Excavator, 2 Trucks, 6.6ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 0.6ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02527.jpg: 384x640 1 Bulldozer, 6.6ms\n",
      "Speed: 0.5ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/09731.jpg: 384x640 1 Excavator, 2 Trucks, 6.6ms\n",
      "Speed: 0.7ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/07627.jpg: 384x640 1 Excavator, 1 Truck, 6.6ms\n",
      "Speed: 0.6ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/00118.jpg: 384x640 1 Excavator, 2 Trucks, 6.6ms\n",
      "Speed: 0.6ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/00039.jpg: 480x640 1 Scraper, 7.8ms\n",
      "Speed: 0.7ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02257.jpg: 384x640 1 Excavator, 1 Truck, 6.9ms\n",
      "Speed: 0.5ms preprocess, 6.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/06505.jpg: 384x640 1 Scraper, 6.6ms\n",
      "Speed: 0.6ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/07944.jpg: 384x640 3 Excavators, 3 Trucks, 6.6ms\n",
      "Speed: 0.7ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02263.jpg: 384x640 2 Excavators, 1 Truck, 6.6ms\n",
      "Speed: 0.6ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/01862.jpg: 480x640 1 Excavator, 7.8ms\n",
      "Speed: 1.0ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/03627.jpg: 384x640 1 Excavator, 1 Truck, 7.0ms\n",
      "Speed: 0.8ms preprocess, 7.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02130.jpg: 384x640 1 Excavator, 6.6ms\n",
      "Speed: 0.6ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/03048.jpg: 384x640 1 Scraper, 6.6ms\n",
      "Speed: 0.6ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/04964.jpg: 384x640 1 Excavator, 1 Truck, 6.6ms\n",
      "Speed: 0.5ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/ppe_0429.jpg: 416x640 19 workers, 7.6ms\n",
      "Speed: 1.2ms preprocess, 7.6ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/05103.jpg: 416x640 1 Truck, 7.2ms\n",
      "Speed: 1.0ms preprocess, 7.2ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/01440.jpg: 384x640 1 Scraper, 7.0ms\n",
      "Speed: 0.6ms preprocess, 7.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/09878.jpg: 384x640 1 Scraper, 6.6ms\n",
      "Speed: 0.6ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02590.jpg: 384x640 1 Excavator, 6.6ms\n",
      "Speed: 0.6ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02537.jpg: 480x640 1 Scraper, 7.8ms\n",
      "Speed: 0.9ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/ppe_0345.jpg: 448x640 3 workers, 7.6ms\n",
      "Speed: 1.1ms preprocess, 7.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/ppe_0261.jpg: 448x640 6 workers, 7.8ms\n",
      "Speed: 0.7ms preprocess, 7.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/08571.jpg: 384x640 1 Excavator, 7.4ms\n",
      "Speed: 0.7ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/06546.jpg: 384x640 1 Excavator, 1 Bulldozer, 7.0ms\n",
      "Speed: 0.6ms preprocess, 7.0ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/05851.jpg: 480x640 1 Scraper, 8.2ms\n",
      "Speed: 0.7ms preprocess, 8.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/08145.jpg: 384x640 1 Bulldozer, 7.4ms\n",
      "Speed: 0.7ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/07368.jpg: 320x640 1 Crane, 1 Bulldozer, 6.8ms\n",
      "Speed: 0.8ms preprocess, 6.8ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02423.jpg: 384x640 1 Excavator, 7.5ms\n",
      "Speed: 0.6ms preprocess, 7.5ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/08407.jpg: 320x640 1 Excavator, 6.7ms\n",
      "Speed: 0.6ms preprocess, 6.7ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02995.jpg: 640x640 1 Truck, 11.5ms\n",
      "Speed: 1.1ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/00995.jpg: 384x640 1 Truck, 7.4ms\n",
      "Speed: 0.7ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/07563.jpg: 384x640 1 Excavator, 1 Compactor, 7.1ms\n",
      "Speed: 0.6ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/04353.jpg: 512x640 1 Crane, 8.2ms\n",
      "Speed: 1.2ms preprocess, 8.2ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/04780.jpg: 384x640 1 Excavator, 7.4ms\n",
      "Speed: 0.6ms preprocess, 7.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02567.jpg: 384x640 1 Excavator, 7.1ms\n",
      "Speed: 0.8ms preprocess, 7.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/00101.jpg: 480x640 1 Crane, 8.2ms\n",
      "Speed: 0.7ms preprocess, 8.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/09205.jpg: 384x640 1 Crane, 7.4ms\n",
      "Speed: 0.7ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/09624.jpg: 352x640 2 Scrapers, 6.9ms\n",
      "Speed: 0.3ms preprocess, 6.9ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/04894.jpg: 352x640 1 Excavator, 6.6ms\n",
      "Speed: 0.4ms preprocess, 6.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02383.jpg: 384x640 1 Truck, 7.4ms\n",
      "Speed: 0.6ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/03095.jpg: 384x640 1 Scraper, 7.1ms\n",
      "Speed: 0.7ms preprocess, 7.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/03140.jpg: 384x640 1 Excavator, 7.1ms\n",
      "Speed: 0.6ms preprocess, 7.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/08855.jpg: 384x640 1 Scraper, 7.1ms\n",
      "Speed: 0.6ms preprocess, 7.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/01111.jpg: 384x640 1 Bulldozer, 1 Truck, 7.1ms\n",
      "Speed: 0.6ms preprocess, 7.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/06700.jpg: 384x640 1 Scraper, 7.1ms\n",
      "Speed: 0.6ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/05809.jpg: 384x640 1 Excavator, 1 Truck, 7.1ms\n",
      "Speed: 0.6ms preprocess, 7.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/ppe_0031.jpg: 384x640 1 worker, 7.1ms\n",
      "Speed: 0.6ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/00814.jpg: 384x640 1 Excavator, 7.1ms\n",
      "Speed: 0.6ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02722.jpg: 384x640 1 Crane, 4 Excavators, 1 Truck, 7.1ms\n",
      "Speed: 0.6ms preprocess, 7.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/05542.jpg: 384x640 1 Compactor, 7.1ms\n",
      "Speed: 0.6ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/ppe_0403.jpg: 640x448 1 worker, 8.0ms\n",
      "Speed: 0.8ms preprocess, 8.0ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/04854.jpg: 448x640 1 Bulldozer, 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/05197.jpg: 384x640 1 Compactor, 7.4ms\n",
      "Speed: 0.6ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/00007.jpg: 384x640 1 Excavator, 7.1ms\n",
      "Speed: 0.6ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/08568.jpg: 384x640 1 Excavator, 1 Compactor, 7.1ms\n",
      "Speed: 0.6ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/03941.jpg: 384x640 1 Bulldozer, 7.1ms\n",
      "Speed: 0.6ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/08359.jpg: 384x640 1 Scraper, 1 Truck, 7.1ms\n",
      "Speed: 0.8ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/00078.jpg: 480x640 1 Compactor, 8.2ms\n",
      "Speed: 0.7ms preprocess, 8.2ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/ppe_1042.jpg: 640x640 1 worker, 11.5ms\n",
      "Speed: 1.1ms preprocess, 11.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/00331.jpg: 384x640 1 Truck, 7.4ms\n",
      "Speed: 0.7ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/09904.jpg: 384x640 1 Truck, 7.1ms\n",
      "Speed: 0.6ms preprocess, 7.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/05914.jpg: 320x640 1 Excavator, 6.6ms\n",
      "Speed: 0.7ms preprocess, 6.6ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/03876.jpg: 384x640 2 Excavators, 8 Trucks, 7.4ms\n",
      "Speed: 0.8ms preprocess, 7.4ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/02528.jpg: 448x640 1 Excavator, 8.1ms\n",
      "Speed: 0.7ms preprocess, 8.1ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/08692.jpg: 384x640 2 Scrapers, 1 Compactor, 7.4ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 0.6ms preprocess, 7.4ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/04499.jpg: 384x640 1 Excavator, 7.1ms\n",
      "Speed: 0.7ms preprocess, 7.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n",
      "\n",
      "image 1/1 /home/aritra/datathon_2023/yolov8/Test_Dataset_100/test_images/05161.jpg: 448x640 1 Crane, 8.1ms\n",
      "Speed: 1.1ms preprocess, 8.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "test_files = os.listdir(path_imgs)\n",
    "\n",
    "for file in test_files:\n",
    "    source = os.path.join(path_imgs,file)\n",
    "    model.predict(source, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d098813c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
